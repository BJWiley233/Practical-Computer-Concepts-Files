{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Brian Wiley <br/>\n",
    "EN.705.601.3VL.SP20 Applied Machine Learning </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "### Applied Machine Learning\n",
    "\n",
    "For this lab we are reviewing the Suicides dataset from the third assignment.  Taking where we left off in class I will test both a weak GaussianNB vs. RandomForestClassifier.  Knowing from assignment 3 that I will be OneHotEncoding the countries, I am going to assume that there will be an increase using an ensemble of the top features.  The question for this dataset is how much.  We will see something interesting as well because the highest ranked feature is extremely correlated with to target variable after slicing that prior to ensemble dropping the lowest correlated features doesn't really change the NB classifier.  It is only after creating the ensemble it increases and only when the ensemble includes this higest ranked column.  Not as good as a dataset and the pre-processed breast cancer for try this NB ensemble as we will see that RandomForest wins out.\n",
    "\n",
    "__1. [20 pts] What is the dependent variable you decided? Why?__\n",
    "\n",
    "As stated in assignment 3 \"The dependent variable should be `suicides/100k pop` so that we can, predict given an example, whether that example will produce a numerical rate equivalent those that fit the examples features. We want to use this column rather than the column suicides_no because the rate is more relative to how large the population could be\"$^{[1]}$ (Wiley, 2020).\n",
    "\n",
    "__2. [20 pts] Set the dependent variable into two categories based on a defensible criteria. (Hint:\n",
    "skirts of the probability density function)__\n",
    "\n",
    "We could also split by quantiles using pandas.qcut and set the quantiles to any percentage we want.  Therefore I am going to use a 75% split where the lower 75% of the column `suicides/100k pop` will be in the low category (value of 0) for suicides and the higher 25% will be in high category (value of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dataset and pre-process from assignment 3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns;\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('datasets/master.csv')\n",
    "\n",
    "df = df.drop(['HDI for year', 'country-year'], axis=1)\n",
    "df.rename(columns={' gdp_for_year ($) ': 'gdp_for_year ($)'}, inplace=True)\n",
    "df['gdp_for_year ($)'] = df['gdp_for_year ($)'].str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "df['age_group float'] = df['age'].map({'5-14 years': 0, \n",
    "                                       '15-24 years': 1, \n",
    "                                       '25-34 years': 2, \n",
    "                                       '35-54 years': 3, \n",
    "                                       '55-74 years': 4, \n",
    "                                       '75+ years': 5})\n",
    "\n",
    "df['generation float'] = df['generation'].map({'Generation Z': 0, \n",
    "                                       'Millenials': 1, \n",
    "                                       'Generation X': 2, \n",
    "                                       'Boomers': 3, \n",
    "                                       'Silent': 4, \n",
    "                                       'G.I. Generation': 5})\n",
    "\n",
    "df.drop(['age', 'generation'], axis=1, inplace=True)\n",
    "\n",
    "## copy dataframe  so we can cut into low and high for `suicides/100k pop`\n",
    "df2 = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x1d620fadcf8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## before cutting the target column lets visualize the 75% quantile in the density plot\n",
    "_75 = df2['suicides/100k pop'].quantile(q=0.75)\n",
    "ax = sns.kdeplot(df2['suicides/100k pop'], shade=True)\n",
    "kde_x, kde_y = ax.lines[0].get_data()\n",
    "ax.fill_between(kde_x, kde_y, where=(kde_x > _75), interpolate=True, \n",
    "                color=\"#56525c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can cut the target column into low and high and set our X and y for the classifiers and OneHotEncode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cut and label\n",
    "df2['suicide_split'] = pd.qcut(df2['suicides/100k pop'], q=[0, .75, 1.], labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.62"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what are the quantiles split at?\n",
    "df2['suicides/100k pop'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop old column\n",
    "df2.drop('suicides/100k pop', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27820, 108)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['year', 'suicides_no', 'population', 'gdp_for_year ($)',\n",
       "       'gdp_per_capita ($)', 'age_group float', 'generation float', 'sex_male',\n",
       "       'country_Antigua and Barbuda', 'country_Argentina',\n",
       "       ...\n",
       "       'country_Thailand', 'country_Trinidad and Tobago', 'country_Turkey',\n",
       "       'country_Turkmenistan', 'country_Ukraine',\n",
       "       'country_United Arab Emirates', 'country_United Kingdom',\n",
       "       'country_United States', 'country_Uruguay', 'country_Uzbekistan'],\n",
       "      dtype='object', length=108)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## set y to target\n",
    "y =  df2.loc[:, df2.columns == 'suicide_split'].values.ravel()\n",
    "\n",
    "## OneHotEncode categorical columns\n",
    "df_ohe = pd.get_dummies(df2, columns=['sex', 'country'], drop_first=True)\n",
    "df_ohe.drop('suicide_split', axis=1, inplace=True)\n",
    "\n",
    "## get X features set\n",
    "X = df_ohe.values\n",
    "print(X.shape)\n",
    "\n",
    "## this will confirm our pearson correlation columns\n",
    "df_ohe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. [20 pts] Develop your classification model(s) to solve your defined problem__\n",
    "\n",
    "I am going to do the GaussianNB and perform basically the same weak and ensemble NB from class.  Then afterwards I am going to try 2 other ensemble classifiers, RandomForest and GradientBoosting along with LinearSVC.  Then we can include a VotingClassifier at the end for the ensemble classifiers.  Lastly for number #5 we will use the VotingClassifier for the classification and for #6 we will use the regressor versions RandomForestRegressor, GradientBoostingRegressor, and LinearSVR respective to get a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. [20 pts] Evaluate (and report) the model performance(s) using some of the standard\n",
    "techniques (e.g. 80-20 split, 10-fold cross validation, etc.).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75003595, 0.24996405])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get priors and also make X an np.ndarray\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "priors = counts/len(y)\n",
    "priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "def eval_classifier(clf, _X, y, k, random_state=0):\n",
    "    ''' \n",
    "    Evaluates k-fold for classifier\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    clf : sklearn classifer\n",
    "    \n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "      Feature set.\n",
    "    y : array-like, shape (n_samples,)\n",
    "      Target values.\n",
    "    k : int\n",
    "      Number of k-folds\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    acc : 1d-array\n",
    "      Accuracy array for k-fold CV \n",
    "    '''\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "    acc = cross_validate(clf, _X, y, cv=kfold, scoring='accuracy')\n",
    "    \n",
    "    return acc['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB CV accuracy=0.75 ±0.002\n"
     ]
    }
   ],
   "source": [
    "acc = eval_classifier(GaussianNB(priors=priors), X, y, k=5)\n",
    "print(f'GaussianNB CV accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try the ensemble from class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weakNB_fit(cols, X, y):\n",
    "    ''' \n",
    "    fits GaussianNB with subset of columns\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    cols : int array-like (feature columns)\n",
    "      Array of selected columns by column number\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "      Feature set.\n",
    "    y : array-like, shape (n_samples,)\n",
    "      Target values.\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    classifier : object\n",
    "      Fit of GaussianNB with X, y\n",
    "    '''\n",
    "    \n",
    "    X_cols = X[:, cols]\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    priors = counts/len(y) \n",
    "    \n",
    "    return GaussianNB(priors=priors).fit(X_cols, y)\n",
    "\n",
    "\n",
    "def weakNB_predict(clf, cols, X):\n",
    "    X_cols = X[:, cols]\n",
    "    \n",
    "    return clf.predict(X_cols), clf.predict_proba(X_cols)\n",
    "\n",
    "\n",
    "def features_random(M, m, num_ensembles=1):\n",
    "    from numpy.random import choice\n",
    "    \n",
    "    return [choice(M, m, replace=False) for _ in range(num_ensembles)]\n",
    "  \n",
    "    \n",
    "def eval_weak(X, y, num_ensembles, num_features, k, random_state=0):\n",
    "    \"\"\"\n",
    "    Doesn't use weakNB_fit or weakNB_predict from class\n",
    "    \n",
    "    So we need priors\n",
    "    \"\"\"\n",
    "    acc = []  \n",
    "    counts = np.unique(y, return_counts=True)[1]\n",
    "    priors = counts/len(y) \n",
    "    cols = features_random(X.shape[1], num_features, num_ensembles)\n",
    "    kfold = StratifiedKFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "    for i in range(num_ensembles):\n",
    "        acc += [cross_validate(GaussianNB(priors=priors),\n",
    "                              X[:, cols[i]], y, \n",
    "                              cv=kfold, scoring='accuracy')['test_score']]\n",
    "        \n",
    "    return acc\n",
    "\n",
    "\n",
    "def ensembleNB_fit(cols, X, y):\n",
    "    ''' \n",
    "    fits GaussianNB with subset of columns\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    cols : array-like, shape (n_ensembles, n_features)\n",
    "      list of ensemble columns\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "      Feature set.\n",
    "    y : array-like, shape (n_samples,)\n",
    "      Target values.\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    classifiers : 1-dimensional object array, shape (n_ensembles,)\n",
    "      Fit of GaussianNB with X, y\n",
    "    '''\n",
    "    n_ensembles = len(cols)\n",
    "    ensemble_clfs = []\n",
    "    for i in range(n_ensembles):\n",
    "        ensemble_clfs += [weakNB_fit(cols[i], X, y)]\n",
    "    \n",
    "    return ensemble_clfs\n",
    "\n",
    "\n",
    "def ensembleNB_predict(ensemble_clfs, cols, X_test):\n",
    "    n_ensembles = len(ensemble_clfs)\n",
    "    assert n_ensembles == len(cols)\n",
    "    y_pred_e = np.empty(shape=(n_ensembles, len(X_test)), dtype=int)\n",
    "    for j in range(n_ensembles):\n",
    "        predictions = weakNB_predict(ensemble_clfs[j], cols[j], X_test)\n",
    "        y_pred_e[j] = predictions[0]\n",
    "    \n",
    "    ## this is covenient function for returning argmax without lambdas\n",
    "    y_pred = np.amax(y_pred_e, axis=0)\n",
    "    \n",
    "    return y_pred\n",
    " \n",
    "   \n",
    "def eval_ensemble(X, y, n_iter, n_ensembles, n_features, k, random_state=0):\n",
    "    acc = []  \n",
    "    ## this array col_lists is just to see which ensembles are using the highest ranked\n",
    "    cols_lists = []\n",
    "    cols = features_random(X.shape[1], n_features, n_ensembles)\n",
    "    cols_lists += cols\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        kfold = StratifiedKFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "        for train_ind, test_ind in kfold.split(X, y):\n",
    "            clf = ensembleNB_fit(cols, X[train_ind], y[train_ind])\n",
    "            y_pred = ensembleNB_predict(clf, cols, X[test_ind])\n",
    "            acc += [accuracy_score(y[test_ind], y_pred)]\n",
    "            \n",
    "    return acc, cols_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I am going to do the ensemble with all features as in class and see what features have the highest rank only because I know it will need it since top 4 are very correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.4255', 'sex_male'),\n",
       " ('0.3108', 'age_group float'),\n",
       " ('0.2911', 'generation float'),\n",
       " ('0.2708', 'suicides_no'),\n",
       " ('0.0761', 'country_Lithuania'),\n",
       " ('0.0700', 'country_Hungary'),\n",
       " ('0.0696', 'country_Russian Federation'),\n",
       " ('0.0687', 'country_Japan'),\n",
       " ('-0.0654', 'country_Guatemala')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('-0.0076', 'country_Montenegro'),\n",
       " ('0.0072', 'country_Puerto Rico'),\n",
       " ('0.0058', 'country_Singapore'),\n",
       " ('-0.0040', 'country_Macau'),\n",
       " ('0.0000', 'country_Cabo Verde')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  7,   5,   6,   1,  59,  47,  82,  53,  45,  35,  13,  43,  65,\n",
       "        74,  56,  54,  58,   8,  91,  27, 102,   4,  37,  15,  10,   3,\n",
       "        19,  94,  39,  92,  16,  95,  98,  18,  80,  44,  46,  41,  52,\n",
       "        22,  29,  14,  63,  73,  75,  31,  79,  17,  40,   0, 105,  69,\n",
       "        97, 104,  32,  60,  87,  12,  62,  25,  71,  76,  23,  28,  51,\n",
       "        30,  85, 100,  38, 106, 107,  20,  50, 103,  48,  93,  99,  70,\n",
       "        96,  84,  57,  88,  83,  42,  55,  72,  49,  64,   9,  11,  77,\n",
       "        33,  81,  36,  26,  34, 101,  86,   2,  68,  66,  90,  21,  67,\n",
       "        78,  89,  61,  24], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Direct correlation between each column of X and the target y\n",
    "corrs = np.array([pearsonr(X[:,j], y)[0] for j in range(X.shape[1])])\n",
    "# Reverse sort, numpy array negation reverses the order\n",
    "ranks = np.argsort(-np.absolute(corrs))\n",
    "\n",
    "rankings = [(f'{corrs[j]:.4f}', df_ohe.columns[j]) for j in ranks]\n",
    "display(rankings[:9])\n",
    "display(rankings[-5:])\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble learners average Acc = 0.25 ±0.000\n",
      "Percentage of ensembles containing the highest rank is 0.06\n"
     ]
    }
   ],
   "source": [
    "n_ensembles = 50\n",
    "acc, cols_lists = eval_ensemble(X, y, n_iter=10, n_ensembles=n_ensembles, n_features=11, k=5, random_state=None)\n",
    "print(f'Ensemble learners average Acc = {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "print('Percentage of ensembles containing the highest rank is',\n",
    "      sum([ranks[0] in arr for arr in cols_lists])/n_ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that only 10% had the feature `sex_male` and without we have nothing really.  Let's trim the top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "delcols = [(i, f'{corrs[i]: .4f}', df_ohe.columns[i]) for i in ranks if np.absolute(corrs[i]) <=.051]\n",
    "delete = [d[0] for d in delcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27820, 35)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_drop = np.delete(np.array(X, copy=True), delete, axis=1)\n",
    "X_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB CV accuracy=0.75 ±0.003\n",
      "Ensemble learners average Acc = 0.25 ±0.000\n",
      "Percentage of ensembles containing the highest rank is 0.3\n"
     ]
    }
   ],
   "source": [
    "## weak NB\n",
    "acc = eval_classifier(GaussianNB(priors=priors), X_drop, y, k=5, random_state=1)\n",
    "print(f'GaussianNB CV accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "\n",
    "## ensemble NB\n",
    "n_ensembles = 50\n",
    "acc, cols_lists = eval_ensemble(X_drop, y, n_iter=5, n_ensembles=n_ensembles, n_features=10, k=5, random_state=0)\n",
    "print(f'Ensemble learners average Acc = {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "print('Percentage of ensembles containing the highest rank is',\n",
    "      sum([ranks[0] in arr for arr in cols_lists])/n_ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the ensemble NB still does bad because not many have the highest correlated feature, `sex_male` for whether male or female. So we need more features in our ensemble as looking at the below we can see that the correlation is high for whether female or male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(color_codes=True)\n",
    "df3 = pd.get_dummies(df, columns=['sex'], drop_first=True)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(4,6), nrows=1, ncols=1)\n",
    "lm = sns.regplot(x='sex_male', y='suicides/100k pop', data=df3, truncate=False, ax=axs)\n",
    "lm.set(xlim=(-.2,1.1), xticks=[0, 1], yticks=[0, 100, 200])\n",
    "\n",
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "X_lm = df_ohe['sex_male'].values.reshape(-1,1)\n",
    "y_lm = df['suicides/100k pop'].values.reshape(-1,1)\n",
    "regr.fit(X_lm, y_lm)\n",
    "slope = round(regr.coef_[0][0], 2)\n",
    "y_int = round(regr.intercept_[0], 2)\n",
    "textstr = f'y = {slope}x + {y_int}'\n",
    "axs.text(.25, 20, textstr)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble learners average Acc = 0.26 ±0.002\n",
      "Percentage of ensembles containing the highest rank is 0.56\n"
     ]
    }
   ],
   "source": [
    "## ensemble NB\n",
    "n_ensembles = 50\n",
    "acc, cols_lists = eval_ensemble(X_drop, y, n_iter=5, n_ensembles=n_ensembles, n_features=20, k=5, random_state=0)\n",
    "print(f'Ensemble learners average Acc = {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "print('Percentage of ensembles containing the highest rank is',\n",
    "      sum([ranks[0] in arr for arr in cols_lists])/n_ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did better.  But also I think we need to check really how many ensembles have the top 2 or 3 features.  Without those we are lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of ensembles containing the 3 highest ranks is 0.2\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of ensembles containing the 3 highest ranks is',\n",
    "      sum([all(x in list_ for x in [ranks[0], ranks[1], ranks[2]]) for list_ in cols_lists])/n_ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble learners average Acc = 0.79 ±0.007\n",
      "Percentage of ensembles containing the 3 highest ranks is 0.54\n"
     ]
    }
   ],
   "source": [
    "n_ensembles = 50\n",
    "acc, cols_lists = eval_ensemble(X_drop, y, n_iter=5, n_ensembles=n_ensembles, n_features=30, k=5, random_state=0)\n",
    "print(f'Ensemble learners average Acc = {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "print('Percentage of ensembles containing the 3 highest ranks is',\n",
    "      sum([all(x in list_ for x in [ranks[0], ranks[1], ranks[2]]) for list_ in cols_lists])/n_ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go.  We beat the weak NB classifier but barely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier CV accuracy=0.98 ±0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC CV accuracy=0.62 ±0.178\n",
      "GradientBoostingClassifier CV accuracy=0.98 ±0.002\n"
     ]
    }
   ],
   "source": [
    "acc = eval_classifier(RandomForestClassifier(n_estimators=200,  \n",
    "                                             random_state=1, \n",
    "                                             n_jobs=4), X, y, k=10)\n",
    "print(f'RandomForestClassifier CV accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "\n",
    "acc = eval_classifier(LinearSVC(max_iter=5000, random_state=1), X, y, k=10)\n",
    "print(f'LinearSVC CV accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "\n",
    "acc = eval_classifier(GradientBoostingClassifier(n_estimators=200, random_state=1), X, y, k=10)\n",
    "print(f'GradientBoostingClassifier CV accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like both ensemble classifiers, RandomForest and GradientBoosting are very good.  Now we can use a VotingClassifier which is also an ensemble and see how it performs when only train on 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=200, n_jobs=4, random_state=1)\n",
    "clf2 = GradientBoostingClassifier(n_estimators=200, random_state=1)\n",
    "clf3 = LinearSVC(max_iter=10000, random_state=1)\n",
    "voting_clf = VotingClassifier(estimators=[('RF', clf1),\n",
    "                                          ('GB', clf2),\n",
    "                                          ('LinSVC', clf3)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=1)\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "print(round(accuracy_score(y_pred, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good.  We can also use VotingRegressor for regression for #6.\n",
    "\n",
    "__5. [20 pts] Using your classifier model, what is the predicted category of your dependent\n",
    "variable for the input: \"year=2000, generation=Generation X, age=20, gender=male\"?__\n",
    "\n",
    "Let's just bring out mapping down from the top so we can get the X and y ready\n",
    "\n",
    "df['age_group float'] = df['age'].map({'5-14 years': 0, \n",
    "                                       '15-24 years': 1, \n",
    "                                       '25-34 years': 2, \n",
    "                                       '35-54 years': 3, \n",
    "                                       '55-74 years': 4, \n",
    "                                       '75+ years': 5})\n",
    "\n",
    "df['generation float'] = df['generation'].map({'Generation Z': 0, \n",
    "                                       'Millenials': 1, \n",
    "                                       'Generation X': 2, \n",
    "                                       'Boomers': 3, \n",
    "                                       'Silent': 4, \n",
    "                                       'G.I. Generation': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>age_group float</th>\n",
       "      <th>generation float</th>\n",
       "      <th>suicide_split</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  age_group float  generation float suicide_split  sex_male\n",
       "0  1987                1                 2             0         1\n",
       "1  1987                3                 4             0         1\n",
       "2  1987                1                 2             0         0\n",
       "3  1987                5                 5             0         1\n",
       "4  1987                2                 3             0         1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = df2.drop(columns=['country', 'suicides_no', 'population', 'gdp_for_year ($)', 'gdp_per_capita ($)'])\n",
    "df4_ohe = pd.get_dummies(df4, columns=['sex'], drop_first=True)\n",
    "df4_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27820, 4)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "X = df4_ohe.loc[:, df4_ohe.columns != 'suicide_split'].values\n",
    "y = df4_ohe.loc[:, df4_ohe.columns == 'suicide_split'].values.ravel()\n",
    "print(X.shape)\n",
    "X_sample = np.array([2000, 1, 2, 1])\n",
    "X_sample = X_sample.reshape(1,-1)\n",
    "print(X_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('RF', clf1),\n",
    "                                          ('GB', clf2),\n",
    "                                          ('LinSVC', clf3)])\n",
    "\n",
    "voting_clf.fit(X, y)\n",
    "y_pred = voting_clf.predict(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So this puts the sample in the low risk category.  Let's see where the average is and if it should be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greater than 16.62 should be high else low.\n"
     ]
    }
   ],
   "source": [
    "## what are the quantiles split at?\n",
    "print('Greater than', df['suicides/100k pop'].quantile(0.75), 'should be high else low.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.712441860465113"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['sex'] == 'male') & \n",
    "    (df['year'] == 2000) &\n",
    "    (df['age_group float'] == 1) &\n",
    "    (df['generation float'] == 2)]['suicides/100k pop'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so we were correct in classifying the sample as low risk category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. [20 pts bonus] Using your (perhaps a different?) model, what is the actual probability of a\n",
    "\"Generation X 20-year-old male living in a country with 40000 gdp_per_capita\"\n",
    "would commit suicide?__\n",
    "\n",
    "df['age_group float'] = df['age'].map({'5-14 years': 0, '15-24 years': 1, '25-34 years': 2, '35-54 years': 3, '55-74 years': 4, '75+ years': 5})\n",
    "\n",
    "df['generation float'] = df['generation'].map({'Generation Z': 0, 'Millenials': 1, 'Generation X': 2, 'Boomers': 3, 'Silent': 4, 'G.I. Generation': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>gdp_for_year ($)</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>age_group float</th>\n",
       "      <th>generation float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>21</td>\n",
       "      <td>312900</td>\n",
       "      <td>6.71</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>308000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>289700</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>274300</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year     sex  suicides_no  population  suicides/100k pop  \\\n",
       "0  Albania  1987    male           21      312900               6.71   \n",
       "1  Albania  1987    male           16      308000               5.19   \n",
       "2  Albania  1987  female           14      289700               4.83   \n",
       "3  Albania  1987    male            1       21800               4.59   \n",
       "4  Albania  1987    male            9      274300               3.28   \n",
       "\n",
       "   gdp_for_year ($)  gdp_per_capita ($)  age_group float  generation float  \n",
       "0      2.156625e+09                 796                1                 2  \n",
       "1      2.156625e+09                 796                3                 4  \n",
       "2      2.156625e+09                 796                1                 2  \n",
       "3      2.156625e+09                 796                5                 5  \n",
       "4      2.156625e+09                 796                2                 3  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suicides/100k pop</th>\n",
       "      <th>gdp_per_capita ($)</th>\n",
       "      <th>age_group float</th>\n",
       "      <th>generation float</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.71</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.19</td>\n",
       "      <td>796</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.83</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.59</td>\n",
       "      <td>796</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.28</td>\n",
       "      <td>796</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   suicides/100k pop  gdp_per_capita ($)  age_group float  generation float  \\\n",
       "0               6.71                 796                1                 2   \n",
       "1               5.19                 796                3                 4   \n",
       "2               4.83                 796                1                 2   \n",
       "3               4.59                 796                5                 5   \n",
       "4               3.28                 796                2                 3   \n",
       "\n",
       "   sex_male  \n",
       "0         1  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drop columns we don't need and OneHotEncode 'sex' column\n",
    "df_reg = df.drop(columns=['country', 'year', 'suicides_no', 'population', 'gdp_for_year ($)'])\n",
    "df_reg_ohe = pd.get_dummies(df_reg, ['sex'], drop_first=True)\n",
    "df_reg_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg = df_reg_ohe.loc[:, df_reg_ohe.columns != 'suicides/100k pop'].values\n",
    "y_reg = df_reg_ohe.loc[:, df_reg_ohe.columns == 'suicides/100k pop'].values.ravel()\n",
    "\n",
    "X_sample = np.array([40000, 1, 2, 1]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjwil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "clf1 = RandomForestRegressor(n_estimators=200, n_jobs=4, random_state=3)\n",
    "clf2 = GradientBoostingRegressor(n_estimators=200, random_state=3)\n",
    "clf3 = LinearSVR(max_iter=10000, random_state=3)\n",
    "voting_clf = VotingRegressor(estimators=[('RF_Reg', clf1),\n",
    "                                          ('GB_Reg', clf2),\n",
    "                                          ('LinSVR', clf3)])\n",
    "\n",
    "voting_clf.fit(X_reg, y_reg)\n",
    "y_pred = voting_clf.predict(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability will commit suicide is 0.0154%.\n"
     ]
    }
   ],
   "source": [
    "print('Probability will commit suicide is ', round(y_pred[0]/100000*100,4), \"%.\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this was not very far off from the probability I got from assignment three which was 0.0155%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
